<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css" />
    <script src="main.js" type="module"></script>
    <link rel="icon" href="assets/favicon.svg" type="image/svg+xml" />
    <title>Writeup</title>
</head>
<body>
    <div class="top-right-button">
        <button onclick="location.href='index.html'">Back</button>
    </div>

    <h1>Writeup</h1>
    <p>
        So far, we have preprocessed the data, chosen the subset to use, and determined the basic storyline of the webpage article. The webpage features three interactable scatter plots that show the top, side, and front views of an individual for a specific sound. Additionally, we included a displacement over time visualization beneath these axes to demonstrate how an individualâ€™s movement varied overall during the sound. There are filtering options based on the data, including group, sound, and individual. We added tooltips to these visualizations to provide additional context and information on the data. Furthermore, we animated the visualizations (and color-encoded them) to visually link the movements between these graphs over time.
    </p>
    <p>
        The most challenging part of the project is our head-tracking mini-experiment. To hook the reader in our project, we aim to simulate the original experiment using head-tracking through their laptop camera and using their data to facilitate comparisons between themself and actual participants of the experiment. Currently, we have code to track head movement from the camera. However, there are issues with how it measures y-axis movement. Additionally, we have to refine the logistics of our mini-simulation to ensure the reader remains engaged and we collect accurate data. Before we can create our exposition, we have to address these problems and then incorporate them into our webpage.
    </p>
</body>
</html>